{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "50f5b5ac-5cb7-4a74-9d65-a4af62283401",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fire_df = spark.read\\\n",
    "    .format(\"csv\")\\\n",
    "        .option(\"header\",\"true\")\\\n",
    "            .option(\"inferSchema\",\"true\")\\\n",
    "                .load(\"/databricks-datasets/learning-spark-v2/sf-fire/sf-fire-calls.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "206547f2-fce7-4d19-8cb3-d41dfcc8a758",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(fire_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "158ccb1d-6a23-4ba8-8605-8e5b96a5ffaf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# change column names to remove spaces\n",
    "new_fire_df = fire_df\\\n",
    "    .withColumnRenamed(\"Call Number\", \"CallNumber\")\\\n",
    "    .withColumnRenamed(\"Unit ID\", \"UnitID\")\\\n",
    "    .withColumnRenamed(\"Incident Number\", \"IncidentNumber\")\\\n",
    "    .withColumnRenamed(\"Call Date\", \"CallDate\")\\\n",
    "    .withColumnRenamed(\"Watch Date\", \"WatchDate\")\\\n",
    "    .withColumnRenamed(\"Call Final Disposition\", \"CallFinalDisposition\")\\\n",
    "    .withColumnRenamed(\"Available DtTm\", \"AvailableDtTm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af1f2761-a3a2-4ad5-9d62-0450506ae5ed",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(new_fire_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "999e41e1-9e58-4a6f-a152-2889b3e61e8f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "new_fire_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9034d386-226a-49c7-be71-b255bdd0c01b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_timestamp, round\n",
    "temp_fire_df = new_fire_df\\\n",
    "    .withColumn(\"AvailableDtTm\", to_timestamp(\"AvailableDtTm\", \"MM/DD/YYYY hh:mm:ss a\"))\n",
    "    .withColumn(\"Delay\", round(\"Delay\",2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f26d0d82-04cb-4ffc-b530-541e330fc24d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# cache dataframe in memory for faster execution\n",
    "fire_df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b081bce-7c7b-4950-bf77-cf3dc3a7c713",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 1. How many distinct types of calls were made to the fire department?\n",
    "\n",
    "# Approach 1 - SQL approach 1. convert data into temporary view 2. run queries\n",
    "\n",
    "# 1. create view\n",
    "# fire_df.createOrReplaceTempView(\"fireView\")\n",
    "# 2. create dataframe\n",
    "q1_sql_df = spark.sql(\"\"\"SELECT COUNT(DISTINCT CallType) FROM global_temp.fireView WHERE CallType is not NULL\"\"\")\n",
    "display(q1_sql_df)\n",
    "\n",
    "# Approach 2 - Dataframe transformations\n",
    "q1_df = fire_df.where(\"CallType is not null\")\\\n",
    "                .select(\"CallType\")\\\n",
    "                .distinct()\n",
    "print(q1_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3846d84c-22e9-4a43-b93a-a16f935a87a4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 2. What are distinct types of calls made to the fire department?\n",
    "\n",
    "q2_df = fire_df.where(\"CallType is not null\")\\\n",
    "                .select(\"CallType\")\\\n",
    "                .distinct()\n",
    "\n",
    "display(q2_df)\n",
    "# SELECT DISTINCT CallType FROM global_temp.fireview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d0ed561-e6c0-4bee-bb7e-9a5f89520e6d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 3. Find out all responses or delayed times greater than 5 mins?\n",
    "\n",
    "q3_df = fire_df.where(\"Delay > 5\")\\\n",
    "                .select(\"*\")\n",
    "\n",
    "display(q3_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c99b633-a523-4da1-a1d3-e7a88e03fc79",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 4. What were the most common call types?\n",
    "\n",
    "q4_df = fire_df.select(\"CallType\")\\\n",
    "                .where(\"CallType is not null\")\\\n",
    "                .groupBy(\"CallType\")\\\n",
    "                .count()\\\n",
    "                .orderBy(\"count\", ascending=False)\\\n",
    "                .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ddc28e71-d66d-4ce1-bfc3-fe2d5294bebe",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 5. What zip codes accounted for the most common calls?\n",
    "\n",
    "q5_df = fire_df.select(\"Zipcode of Incident\")\\\n",
    "                .groupBy(\"Zipcode of Incident\")\\\n",
    "                .count()\\\n",
    "                .orderBy(\"count\",ascending=False)\\\n",
    "                .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d5619def-1fca-4517-821f-96e7e0f00c7e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 6. What San Francisco neighborhoods are in the zip codes 94102 and 94103\n",
    "\n",
    "q6_df = fire_df.where(\"`Zipcode of Incident` = 94102 OR `Zipcode of Incident`= 94103 AND City='SF'\")\\\n",
    "                .select(\"Neighborhood\")\\\n",
    "                .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "24cf98c3-3939-412c-9180-ee094c408647",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 7. What was the sum of all calls, average, min, and max of the call response times?\n",
    "\n",
    "from pyspark.sql.functions import sum, avg, min, max\n",
    "\n",
    "q7_df = fire_df.select(\n",
    "                sum(\"Delay\").alias(\"Sum_of_Calls\"),\n",
    "                avg(\"Delay\").alias(\"Avg_Delay\"),\n",
    "                min(\"Delay\").alias(\"Min_Delay\"),\n",
    "                max(\"Delay\").alias(\"Max_Delay\")\n",
    "                )\\\n",
    "                .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bf1b36af-d558-464c-9b20-359dde0bd36d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 8. How many distinct years of data are in the CSV file?\n",
    "from pyspark.sql.functions import year\n",
    "q8_df = fire_df.select(year(\"Call Date\"))\\\n",
    "                .distinct()\n",
    "\n",
    "print(q8_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9cf52dca-f93a-402d-8022-e96820455879",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#  9. What week of the year in 2018 had the most fire calls?\n",
    "from pyspark.sql.functions import weekofyear, year, count\n",
    "\n",
    "q9_df = fire_df.filter(year(\"Call Date\") == 2018)\\\n",
    "                .groupBy(weekofyear(\"Call Date\").alias(\"WeekOfYear\"))\\\n",
    "                .agg(count(\"*\").alias(\"CallCount\"))\\\n",
    "                .orderBy(\"CallCount\", ascending=False)\\\n",
    "                .limit(1)\\\n",
    "                .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e13a8668-ce39-4d0b-9b36-4a9f5a28e4d5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#  10. What neighborhoods in San Francisco had the worst response time in 2018?\n",
    "\n",
    "from pyspark.sql.functions import col, year, avg\n",
    "\n",
    "q10_df = fire_df.filter((year(\"Call Date\") == 2018) & (col(\"Neighborhood\").isNotNull()))\\\n",
    "                .groupBy(\"Neighborhood\")\\\n",
    "                .agg(avg(\"Delay\").alias(\"Avg_response_time\"))\\\n",
    "                .orderBy(\"Avg_response_time\", ascending=False)\\\n",
    "                .show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Spark Transformations",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
